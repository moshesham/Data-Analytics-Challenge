# !/bin/bash
echo "ðŸš€ Generating the professional-grade 30-Day Data Challenge project skeleton..."

# Root Project Directory
PROJECT_NAME="Data-Analytics-Challenge"
mkdir -p "$PROJECT_NAME"
cd "$PROJECT_NAME"

# === 1. Create Core Directories ===
echo "Creating core directories..."
mkdir -p .github/ISSUE_TEMPLATE
mkdir -p src
mkdir -p solutions
mkdir -p scripts

# === 2. Create Root Files with Content ===
echo "Creating root configuration files..."

# .gitignore (for git)
cat > .gitignore << EOL
# Environments
.env
.venv/
env/
venv/
__pycache__/

# IDE / Editor specific
.vscode/
.idea/

# Jupyter
.ipynb_checkpoints/

# Data (recommend using Git LFS or a download script)
# *.csv
# *.json
# *.parquet
# *.zip

# Build artifacts & logs
*.html
*.pdf
dist/
build/
*.log

# Docker
docker-compose.override.yml
EOL

# .dockerignore (for docker build context)
cat > .dockerignore << EOL
# This file prevents large or unnecessary files from being sent to the
# Docker daemon, speeding up the 'docker build' process significantly.

# Ignore everything by default
**

# Whitelist only the files needed to build the image
!environment.yml
EOL

# Main README.md
cat > README.md << EOL
# 30-Day Data Challenge

Welcome! This repository is designed to help you build a strong daily habit of coding and problem-solving with data.

## Setup

Docker is the recommended method as it provides a perfect, isolated environment with a single command.

### Option 1: Docker (Recommended)
1.  Install [Docker Desktop](https://www.docker.com/products/docker-desktop/).
2.  Open a terminal in the project root directory.
3.  Run the command: \`docker-compose up --build\`
4.  Wait for the logs to show that Jupyter Lab is running.
5.  Open your browser and navigate to **http://localhost:8888**. Your work will be saved directly to your local files.

### Option 2: Conda (Manual Setup)
1.  Install [Miniconda](https://docs.conda.io/en/latest/miniconda.html).
2.  Create the environment: \`conda env create -f environment.yml\`
3.  Activate the environment: \`conda activate 30day-challenge\`
4.  Start Jupyter Lab: \`jupyter lab\`

## Challenge Index

<!-- TOC-START -->
*This table of contents can be auto-generated by running a script.*
<!-- TOC-END -->
EOL

# environment.yml
cat > environment.yml << EOL
name: 30day-challenge
channels:
  - conda-forge
dependencies:
  - python=3.9
  - jupyterlab
  - pandas
  - numpy
  - scikit-learn
  - matplotlib
  - seaborn
  - pyarrow  # For Parquet support
EOL

# Dockerfile (Optimized)
cat > Dockerfile << EOL
# This Dockerfile creates a lean, optimized environment for the challenge.
# It does NOT copy the project code, which is handled by the docker-compose volume.

FROM jupyter/scipy-notebook:latest

WORKDIR /home/jovyan/work

# Copy ONLY the environment file, leveraging .dockerignore for a fast build context.
COPY environment.yml .

# Update the base conda environment and clean up to minimize image size.
RUN conda env update -n base -f environment.yml && \\
    conda clean --all -f -y
EOL

# docker-compose.yml (Improved UX)
cat > docker-compose.yml << EOL
version: '3.8'
services:
  challenge-env:
    build: .
    container_name: 30-day-data-challenge
    ports:
      - "8888:8888"
    volumes:
      # This mounts your local project folder into the container.
      # It's the most important line: your work is saved on your machine!
      - .:/home/jovyan/work
    # Custom command for better UX: starts Jupyter Lab without a password or token.
    command: >
      jupyter lab
      --ip=0.0.0.0
      --port=8888
      --no-browser
      --allow-root
      --NotebookApp.token=''
      --NotebookApp.password=''
EOL

# Other standard files
touch LICENSE CONTRIBUTING.md CODE_OF_CONDUCT.md
echo "### SPOILER ALERT! \n\nThis directory contains the solutions to the challenges. Please attempt the challenges on your own before looking at these files." > solutions/README.md

# === 3. Generate Daily Challenge & Solution Folders (Identical to your script) ===
echo "Generating folders for all 30 days..."
for i in $(seq -w 1 30)
do
  DAY_DIR="Day_${i}_Topic"
  mkdir -p "$DAY_DIR/data"
  mkdir -p "solutions/$DAY_DIR"
  echo "# Day $i: Challenge Topic" > "$DAY_DIR/README.md"
  echo -e "\n## Objective\n\n- A clear statement of the day's goal." >> "$DAY_DIR/README.md"
  echo -e "\n## Tasks\n\n1. Task one.\n2. Task two." >> "$DAY_DIR/README.md"
  # Starter Notebook
  echo '{ "cells": [ { "cell_type": "markdown", "metadata": {}, "source": [ "# Day '"$i"': Challenge Topic" ] }, { "cell_type": "markdown", "metadata": {}, "source": [ "## Setup\n", "Add project root to the Python path to allow importing from `src`." ] }, { "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [ "import sys\n", "import os\n", "if \"../\" not in sys.path:\n", "  sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\")))" ] }, { "cell_type": "markdown", "metadata": {}, "source": [ "## Task 1: Load the Data" ] }, { "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [] } ], "metadata": { "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" } }, "nbformat": 4, "nbformat_minor": 2 }' > "$DAY_DIR/challenge.ipynb"
  # Placeholder for solution
  touch "solutions/$DAY_DIR/solution.ipynb"
done

# === 4. Generate Utility Scripts and Src files ===
echo "Creating utility scripts and src files..."
touch src/__init__.py
echo "# Contains data-related helper functions (e.g., download_data)" > src/data_utils.py
echo "# Contains plotting helper functions (e.g., set_plot_style)" > src/plotting_utils.py
echo "# Script to auto-generate the Table of Contents in README.md" > scripts/generate_toc.py

echo "âœ… Skeleton generation complete!"
echo "Navigate into the '$PROJECT_NAME' directory and run 'docker-compose up --build' to start."
cd ..
chmod +x generate_skeleton.sh
./generate_skeleton.sh